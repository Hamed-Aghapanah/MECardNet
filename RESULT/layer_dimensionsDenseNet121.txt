layer 1 => input_tensor                  [(None, 256, 256, 3)]                     param = 1.0 
layer 2 => zero_padding2d_22             (None, 262, 262, 3)                  param = 205932 
layer 3 => conv1/conv                    (None, 128, 128, 64)                  param = 1048576 
layer 4 => conv1/bn                      (None, 128, 128, 64)                  param = 1048576 
layer 5 => conv1/relu                    (None, 128, 128, 64)                  param = 1048576 
layer 6 => zero_padding2d_23             (None, 130, 130, 64)                  param = 1081600 
layer 7 => pool1                         (None, 64, 64, 64)                  param = 262144 
layer 8 => conv2_block1_0_bn             (None, 64, 64, 64)                  param = 262144 
layer 9 => conv2_block1_0_relu           (None, 64, 64, 64)                  param = 262144 
layer 10 => conv2_block1_1_conv           (None, 64, 64, 128)                  param = 524288 
layer 11 => conv2_block1_1_bn             (None, 64, 64, 128)                  param = 524288 
layer 12 => conv2_block1_1_relu           (None, 64, 64, 128)                  param = 524288 
layer 13 => conv2_block1_2_conv           (None, 64, 64, 32)                  param = 131072 
layer 14 => conv2_block1_concat           (None, 64, 64, 96)                  param = 393216 
layer 15 => conv2_block2_0_bn             (None, 64, 64, 96)                  param = 393216 
layer 16 => conv2_block2_0_relu           (None, 64, 64, 96)                  param = 393216 
layer 17 => conv2_block2_1_conv           (None, 64, 64, 128)                  param = 524288 
layer 18 => conv2_block2_1_bn             (None, 64, 64, 128)                  param = 524288 
layer 19 => conv2_block2_1_relu           (None, 64, 64, 128)                  param = 524288 
layer 20 => conv2_block2_2_conv           (None, 64, 64, 32)                  param = 131072 
layer 21 => conv2_block2_concat           (None, 64, 64, 128)                  param = 524288 
layer 22 => conv2_block3_0_bn             (None, 64, 64, 128)                  param = 524288 
layer 23 => conv2_block3_0_relu           (None, 64, 64, 128)                  param = 524288 
layer 24 => conv2_block3_1_conv           (None, 64, 64, 128)                  param = 524288 
layer 25 => conv2_block3_1_bn             (None, 64, 64, 128)                  param = 524288 
layer 26 => conv2_block3_1_relu           (None, 64, 64, 128)                  param = 524288 
layer 27 => conv2_block3_2_conv           (None, 64, 64, 32)                  param = 131072 
layer 28 => conv2_block3_concat           (None, 64, 64, 160)                  param = 655360 
layer 29 => conv2_block4_0_bn             (None, 64, 64, 160)                  param = 655360 
layer 30 => conv2_block4_0_relu           (None, 64, 64, 160)                  param = 655360 
layer 31 => conv2_block4_1_conv           (None, 64, 64, 128)                  param = 524288 
layer 32 => conv2_block4_1_bn             (None, 64, 64, 128)                  param = 524288 
layer 33 => conv2_block4_1_relu           (None, 64, 64, 128)                  param = 524288 
layer 34 => conv2_block4_2_conv           (None, 64, 64, 32)                  param = 131072 
layer 35 => conv2_block4_concat           (None, 64, 64, 192)                  param = 786432 
layer 36 => conv2_block5_0_bn             (None, 64, 64, 192)                  param = 786432 
layer 37 => conv2_block5_0_relu           (None, 64, 64, 192)                  param = 786432 
layer 38 => conv2_block5_1_conv           (None, 64, 64, 128)                  param = 524288 
layer 39 => conv2_block5_1_bn             (None, 64, 64, 128)                  param = 524288 
layer 40 => conv2_block5_1_relu           (None, 64, 64, 128)                  param = 524288 
layer 41 => conv2_block5_2_conv           (None, 64, 64, 32)                  param = 131072 
layer 42 => conv2_block5_concat           (None, 64, 64, 224)                  param = 917504 
layer 43 => conv2_block6_0_bn             (None, 64, 64, 224)                  param = 917504 
layer 44 => conv2_block6_0_relu           (None, 64, 64, 224)                  param = 917504 
layer 45 => conv2_block6_1_conv           (None, 64, 64, 128)                  param = 524288 
layer 46 => conv2_block6_1_bn             (None, 64, 64, 128)                  param = 524288 
layer 47 => conv2_block6_1_relu           (None, 64, 64, 128)                  param = 524288 
layer 48 => conv2_block6_2_conv           (None, 64, 64, 32)                  param = 131072 
layer 49 => conv2_block6_concat           (None, 64, 64, 256)                  param = 1048576 
layer 50 => pool2_bn                      (None, 64, 64, 256)                  param = 1048576 
layer 51 => pool2_relu                    (None, 64, 64, 256)                  param = 1048576 
layer 52 => pool2_conv                    (None, 64, 64, 128)                  param = 524288 
layer 53 => pool2_pool                    (None, 32, 32, 128)                  param = 131072 
layer 54 => conv3_block1_0_bn             (None, 32, 32, 128)                  param = 131072 
layer 55 => conv3_block1_0_relu           (None, 32, 32, 128)                  param = 131072 
layer 56 => conv3_block1_1_conv           (None, 32, 32, 128)                  param = 131072 
layer 57 => conv3_block1_1_bn             (None, 32, 32, 128)                  param = 131072 
layer 58 => conv3_block1_1_relu           (None, 32, 32, 128)                  param = 131072 
layer 59 => conv3_block1_2_conv           (None, 32, 32, 32)                  param = 32768 
layer 60 => conv3_block1_concat           (None, 32, 32, 160)                  param = 163840 
layer 61 => conv3_block2_0_bn             (None, 32, 32, 160)                  param = 163840 
layer 62 => conv3_block2_0_relu           (None, 32, 32, 160)                  param = 163840 
layer 63 => conv3_block2_1_conv           (None, 32, 32, 128)                  param = 131072 
layer 64 => conv3_block2_1_bn             (None, 32, 32, 128)                  param = 131072 
layer 65 => conv3_block2_1_relu           (None, 32, 32, 128)                  param = 131072 
layer 66 => conv3_block2_2_conv           (None, 32, 32, 32)                  param = 32768 
layer 67 => conv3_block2_concat           (None, 32, 32, 192)                  param = 196608 
layer 68 => conv3_block3_0_bn             (None, 32, 32, 192)                  param = 196608 
layer 69 => conv3_block3_0_relu           (None, 32, 32, 192)                  param = 196608 
layer 70 => conv3_block3_1_conv           (None, 32, 32, 128)                  param = 131072 
layer 71 => conv3_block3_1_bn             (None, 32, 32, 128)                  param = 131072 
layer 72 => conv3_block3_1_relu           (None, 32, 32, 128)                  param = 131072 
layer 73 => conv3_block3_2_conv           (None, 32, 32, 32)                  param = 32768 
layer 74 => conv3_block3_concat           (None, 32, 32, 224)                  param = 229376 
layer 75 => conv3_block4_0_bn             (None, 32, 32, 224)                  param = 229376 
layer 76 => conv3_block4_0_relu           (None, 32, 32, 224)                  param = 229376 
layer 77 => conv3_block4_1_conv           (None, 32, 32, 128)                  param = 131072 
layer 78 => conv3_block4_1_bn             (None, 32, 32, 128)                  param = 131072 
layer 79 => conv3_block4_1_relu           (None, 32, 32, 128)                  param = 131072 
layer 80 => conv3_block4_2_conv           (None, 32, 32, 32)                  param = 32768 
layer 81 => conv3_block4_concat           (None, 32, 32, 256)                  param = 262144 
layer 82 => conv3_block5_0_bn             (None, 32, 32, 256)                  param = 262144 
layer 83 => conv3_block5_0_relu           (None, 32, 32, 256)                  param = 262144 
layer 84 => conv3_block5_1_conv           (None, 32, 32, 128)                  param = 131072 
layer 85 => conv3_block5_1_bn             (None, 32, 32, 128)                  param = 131072 
layer 86 => conv3_block5_1_relu           (None, 32, 32, 128)                  param = 131072 
layer 87 => conv3_block5_2_conv           (None, 32, 32, 32)                  param = 32768 
layer 88 => conv3_block5_concat           (None, 32, 32, 288)                  param = 294912 
layer 89 => conv3_block6_0_bn             (None, 32, 32, 288)                  param = 294912 
layer 90 => conv3_block6_0_relu           (None, 32, 32, 288)                  param = 294912 
layer 91 => conv3_block6_1_conv           (None, 32, 32, 128)                  param = 131072 
layer 92 => conv3_block6_1_bn             (None, 32, 32, 128)                  param = 131072 
layer 93 => conv3_block6_1_relu           (None, 32, 32, 128)                  param = 131072 
layer 94 => conv3_block6_2_conv           (None, 32, 32, 32)                  param = 32768 
layer 95 => conv3_block6_concat           (None, 32, 32, 320)                  param = 327680 
layer 96 => conv3_block7_0_bn             (None, 32, 32, 320)                  param = 327680 
layer 97 => conv3_block7_0_relu           (None, 32, 32, 320)                  param = 327680 
layer 98 => conv3_block7_1_conv           (None, 32, 32, 128)                  param = 131072 
layer 99 => conv3_block7_1_bn             (None, 32, 32, 128)                  param = 131072 
layer 100 => conv3_block7_1_relu           (None, 32, 32, 128)                  param = 131072 
layer 101 => conv3_block7_2_conv           (None, 32, 32, 32)                  param = 32768 
layer 102 => conv3_block7_concat           (None, 32, 32, 352)                  param = 360448 
layer 103 => conv3_block8_0_bn             (None, 32, 32, 352)                  param = 360448 
layer 104 => conv3_block8_0_relu           (None, 32, 32, 352)                  param = 360448 
layer 105 => conv3_block8_1_conv           (None, 32, 32, 128)                  param = 131072 
layer 106 => conv3_block8_1_bn             (None, 32, 32, 128)                  param = 131072 
layer 107 => conv3_block8_1_relu           (None, 32, 32, 128)                  param = 131072 
layer 108 => conv3_block8_2_conv           (None, 32, 32, 32)                  param = 32768 
layer 109 => conv3_block8_concat           (None, 32, 32, 384)                  param = 393216 
layer 110 => conv3_block9_0_bn             (None, 32, 32, 384)                  param = 393216 
layer 111 => conv3_block9_0_relu           (None, 32, 32, 384)                  param = 393216 
layer 112 => conv3_block9_1_conv           (None, 32, 32, 128)                  param = 131072 
layer 113 => conv3_block9_1_bn             (None, 32, 32, 128)                  param = 131072 
layer 114 => conv3_block9_1_relu           (None, 32, 32, 128)                  param = 131072 
layer 115 => conv3_block9_2_conv           (None, 32, 32, 32)                  param = 32768 
layer 116 => conv3_block9_concat           (None, 32, 32, 416)                  param = 425984 
layer 117 => conv3_block10_0_bn            (None, 32, 32, 416)                  param = 425984 
layer 118 => conv3_block10_0_relu          (None, 32, 32, 416)                  param = 425984 
layer 119 => conv3_block10_1_conv          (None, 32, 32, 128)                  param = 131072 
layer 120 => conv3_block10_1_bn            (None, 32, 32, 128)                  param = 131072 
layer 121 => conv3_block10_1_relu          (None, 32, 32, 128)                  param = 131072 
layer 122 => conv3_block10_2_conv          (None, 32, 32, 32)                  param = 32768 
layer 123 => conv3_block10_concat          (None, 32, 32, 448)                  param = 458752 
layer 124 => conv3_block11_0_bn            (None, 32, 32, 448)                  param = 458752 
layer 125 => conv3_block11_0_relu          (None, 32, 32, 448)                  param = 458752 
layer 126 => conv3_block11_1_conv          (None, 32, 32, 128)                  param = 131072 
layer 127 => conv3_block11_1_bn            (None, 32, 32, 128)                  param = 131072 
layer 128 => conv3_block11_1_relu          (None, 32, 32, 128)                  param = 131072 
layer 129 => conv3_block11_2_conv          (None, 32, 32, 32)                  param = 32768 
layer 130 => conv3_block11_concat          (None, 32, 32, 480)                  param = 491520 
layer 131 => conv3_block12_0_bn            (None, 32, 32, 480)                  param = 491520 
layer 132 => conv3_block12_0_relu          (None, 32, 32, 480)                  param = 491520 
layer 133 => conv3_block12_1_conv          (None, 32, 32, 128)                  param = 131072 
layer 134 => conv3_block12_1_bn            (None, 32, 32, 128)                  param = 131072 
layer 135 => conv3_block12_1_relu          (None, 32, 32, 128)                  param = 131072 
layer 136 => conv3_block12_2_conv          (None, 32, 32, 32)                  param = 32768 
layer 137 => conv3_block12_concat          (None, 32, 32, 512)                  param = 524288 
layer 138 => pool3_bn                      (None, 32, 32, 512)                  param = 524288 
layer 139 => pool3_relu                    (None, 32, 32, 512)                  param = 524288 
layer 140 => pool3_conv                    (None, 32, 32, 256)                  param = 262144 
layer 141 => pool3_pool                    (None, 16, 16, 256)                  param = 65536 
layer 142 => conv4_block1_0_bn             (None, 16, 16, 256)                  param = 65536 
layer 143 => conv4_block1_0_relu           (None, 16, 16, 256)                  param = 65536 
layer 144 => conv4_block1_1_conv           (None, 16, 16, 128)                  param = 32768 
layer 145 => conv4_block1_1_bn             (None, 16, 16, 128)                  param = 32768 
layer 146 => conv4_block1_1_relu           (None, 16, 16, 128)                  param = 32768 
layer 147 => conv4_block1_2_conv           (None, 16, 16, 32)                  param = 8192 
layer 148 => conv4_block1_concat           (None, 16, 16, 288)                  param = 73728 
layer 149 => conv4_block2_0_bn             (None, 16, 16, 288)                  param = 73728 
layer 150 => conv4_block2_0_relu           (None, 16, 16, 288)                  param = 73728 
layer 151 => conv4_block2_1_conv           (None, 16, 16, 128)                  param = 32768 
layer 152 => conv4_block2_1_bn             (None, 16, 16, 128)                  param = 32768 
layer 153 => conv4_block2_1_relu           (None, 16, 16, 128)                  param = 32768 
layer 154 => conv4_block2_2_conv           (None, 16, 16, 32)                  param = 8192 
layer 155 => conv4_block2_concat           (None, 16, 16, 320)                  param = 81920 
layer 156 => conv4_block3_0_bn             (None, 16, 16, 320)                  param = 81920 
layer 157 => conv4_block3_0_relu           (None, 16, 16, 320)                  param = 81920 
layer 158 => conv4_block3_1_conv           (None, 16, 16, 128)                  param = 32768 
layer 159 => conv4_block3_1_bn             (None, 16, 16, 128)                  param = 32768 
layer 160 => conv4_block3_1_relu           (None, 16, 16, 128)                  param = 32768 
layer 161 => conv4_block3_2_conv           (None, 16, 16, 32)                  param = 8192 
layer 162 => conv4_block3_concat           (None, 16, 16, 352)                  param = 90112 
layer 163 => conv4_block4_0_bn             (None, 16, 16, 352)                  param = 90112 
layer 164 => conv4_block4_0_relu           (None, 16, 16, 352)                  param = 90112 
layer 165 => conv4_block4_1_conv           (None, 16, 16, 128)                  param = 32768 
layer 166 => conv4_block4_1_bn             (None, 16, 16, 128)                  param = 32768 
layer 167 => conv4_block4_1_relu           (None, 16, 16, 128)                  param = 32768 
layer 168 => conv4_block4_2_conv           (None, 16, 16, 32)                  param = 8192 
layer 169 => conv4_block4_concat           (None, 16, 16, 384)                  param = 98304 
layer 170 => conv4_block5_0_bn             (None, 16, 16, 384)                  param = 98304 
layer 171 => conv4_block5_0_relu           (None, 16, 16, 384)                  param = 98304 
layer 172 => conv4_block5_1_conv           (None, 16, 16, 128)                  param = 32768 
layer 173 => conv4_block5_1_bn             (None, 16, 16, 128)                  param = 32768 
layer 174 => conv4_block5_1_relu           (None, 16, 16, 128)                  param = 32768 
layer 175 => conv4_block5_2_conv           (None, 16, 16, 32)                  param = 8192 
layer 176 => conv4_block5_concat           (None, 16, 16, 416)                  param = 106496 
layer 177 => conv4_block6_0_bn             (None, 16, 16, 416)                  param = 106496 
layer 178 => conv4_block6_0_relu           (None, 16, 16, 416)                  param = 106496 
layer 179 => conv4_block6_1_conv           (None, 16, 16, 128)                  param = 32768 
layer 180 => conv4_block6_1_bn             (None, 16, 16, 128)                  param = 32768 
layer 181 => conv4_block6_1_relu           (None, 16, 16, 128)                  param = 32768 
layer 182 => conv4_block6_2_conv           (None, 16, 16, 32)                  param = 8192 
layer 183 => conv4_block6_concat           (None, 16, 16, 448)                  param = 114688 
layer 184 => conv4_block7_0_bn             (None, 16, 16, 448)                  param = 114688 
layer 185 => conv4_block7_0_relu           (None, 16, 16, 448)                  param = 114688 
layer 186 => conv4_block7_1_conv           (None, 16, 16, 128)                  param = 32768 
layer 187 => conv4_block7_1_bn             (None, 16, 16, 128)                  param = 32768 
layer 188 => conv4_block7_1_relu           (None, 16, 16, 128)                  param = 32768 
layer 189 => conv4_block7_2_conv           (None, 16, 16, 32)                  param = 8192 
layer 190 => conv4_block7_concat           (None, 16, 16, 480)                  param = 122880 
layer 191 => conv4_block8_0_bn             (None, 16, 16, 480)                  param = 122880 
layer 192 => conv4_block8_0_relu           (None, 16, 16, 480)                  param = 122880 
layer 193 => conv4_block8_1_conv           (None, 16, 16, 128)                  param = 32768 
layer 194 => conv4_block8_1_bn             (None, 16, 16, 128)                  param = 32768 
layer 195 => conv4_block8_1_relu           (None, 16, 16, 128)                  param = 32768 
layer 196 => conv4_block8_2_conv           (None, 16, 16, 32)                  param = 8192 
layer 197 => conv4_block8_concat           (None, 16, 16, 512)                  param = 131072 
layer 198 => conv4_block9_0_bn             (None, 16, 16, 512)                  param = 131072 
layer 199 => conv4_block9_0_relu           (None, 16, 16, 512)                  param = 131072 
layer 200 => conv4_block9_1_conv           (None, 16, 16, 128)                  param = 32768 
layer 201 => conv4_block9_1_bn             (None, 16, 16, 128)                  param = 32768 
layer 202 => conv4_block9_1_relu           (None, 16, 16, 128)                  param = 32768 
layer 203 => conv4_block9_2_conv           (None, 16, 16, 32)                  param = 8192 
layer 204 => conv4_block9_concat           (None, 16, 16, 544)                  param = 139264 
layer 205 => conv4_block10_0_bn            (None, 16, 16, 544)                  param = 139264 
layer 206 => conv4_block10_0_relu          (None, 16, 16, 544)                  param = 139264 
layer 207 => conv4_block10_1_conv          (None, 16, 16, 128)                  param = 32768 
layer 208 => conv4_block10_1_bn            (None, 16, 16, 128)                  param = 32768 
layer 209 => conv4_block10_1_relu          (None, 16, 16, 128)                  param = 32768 
layer 210 => conv4_block10_2_conv          (None, 16, 16, 32)                  param = 8192 
layer 211 => conv4_block10_concat          (None, 16, 16, 576)                  param = 147456 
layer 212 => conv4_block11_0_bn            (None, 16, 16, 576)                  param = 147456 
layer 213 => conv4_block11_0_relu          (None, 16, 16, 576)                  param = 147456 
layer 214 => conv4_block11_1_conv          (None, 16, 16, 128)                  param = 32768 
layer 215 => conv4_block11_1_bn            (None, 16, 16, 128)                  param = 32768 
layer 216 => conv4_block11_1_relu          (None, 16, 16, 128)                  param = 32768 
layer 217 => conv4_block11_2_conv          (None, 16, 16, 32)                  param = 8192 
layer 218 => conv4_block11_concat          (None, 16, 16, 608)                  param = 155648 
layer 219 => conv4_block12_0_bn            (None, 16, 16, 608)                  param = 155648 
layer 220 => conv4_block12_0_relu          (None, 16, 16, 608)                  param = 155648 
layer 221 => conv4_block12_1_conv          (None, 16, 16, 128)                  param = 32768 
layer 222 => conv4_block12_1_bn            (None, 16, 16, 128)                  param = 32768 
layer 223 => conv4_block12_1_relu          (None, 16, 16, 128)                  param = 32768 
layer 224 => conv4_block12_2_conv          (None, 16, 16, 32)                  param = 8192 
layer 225 => conv4_block12_concat          (None, 16, 16, 640)                  param = 163840 
layer 226 => conv4_block13_0_bn            (None, 16, 16, 640)                  param = 163840 
layer 227 => conv4_block13_0_relu          (None, 16, 16, 640)                  param = 163840 
layer 228 => conv4_block13_1_conv          (None, 16, 16, 128)                  param = 32768 
layer 229 => conv4_block13_1_bn            (None, 16, 16, 128)                  param = 32768 
layer 230 => conv4_block13_1_relu          (None, 16, 16, 128)                  param = 32768 
layer 231 => conv4_block13_2_conv          (None, 16, 16, 32)                  param = 8192 
layer 232 => conv4_block13_concat          (None, 16, 16, 672)                  param = 172032 
layer 233 => conv4_block14_0_bn            (None, 16, 16, 672)                  param = 172032 
layer 234 => conv4_block14_0_relu          (None, 16, 16, 672)                  param = 172032 
layer 235 => conv4_block14_1_conv          (None, 16, 16, 128)                  param = 32768 
layer 236 => conv4_block14_1_bn            (None, 16, 16, 128)                  param = 32768 
layer 237 => conv4_block14_1_relu          (None, 16, 16, 128)                  param = 32768 
layer 238 => conv4_block14_2_conv          (None, 16, 16, 32)                  param = 8192 
layer 239 => conv4_block14_concat          (None, 16, 16, 704)                  param = 180224 
layer 240 => conv4_block15_0_bn            (None, 16, 16, 704)                  param = 180224 
layer 241 => conv4_block15_0_relu          (None, 16, 16, 704)                  param = 180224 
layer 242 => conv4_block15_1_conv          (None, 16, 16, 128)                  param = 32768 
layer 243 => conv4_block15_1_bn            (None, 16, 16, 128)                  param = 32768 
layer 244 => conv4_block15_1_relu          (None, 16, 16, 128)                  param = 32768 
layer 245 => conv4_block15_2_conv          (None, 16, 16, 32)                  param = 8192 
layer 246 => conv4_block15_concat          (None, 16, 16, 736)                  param = 188416 
layer 247 => conv4_block16_0_bn            (None, 16, 16, 736)                  param = 188416 
layer 248 => conv4_block16_0_relu          (None, 16, 16, 736)                  param = 188416 
layer 249 => conv4_block16_1_conv          (None, 16, 16, 128)                  param = 32768 
layer 250 => conv4_block16_1_bn            (None, 16, 16, 128)                  param = 32768 
layer 251 => conv4_block16_1_relu          (None, 16, 16, 128)                  param = 32768 
layer 252 => conv4_block16_2_conv          (None, 16, 16, 32)                  param = 8192 
layer 253 => conv4_block16_concat          (None, 16, 16, 768)                  param = 196608 
layer 254 => conv4_block17_0_bn            (None, 16, 16, 768)                  param = 196608 
layer 255 => conv4_block17_0_relu          (None, 16, 16, 768)                  param = 196608 
layer 256 => conv4_block17_1_conv          (None, 16, 16, 128)                  param = 32768 
layer 257 => conv4_block17_1_bn            (None, 16, 16, 128)                  param = 32768 
layer 258 => conv4_block17_1_relu          (None, 16, 16, 128)                  param = 32768 
layer 259 => conv4_block17_2_conv          (None, 16, 16, 32)                  param = 8192 
layer 260 => conv4_block17_concat          (None, 16, 16, 800)                  param = 204800 
layer 261 => conv4_block18_0_bn            (None, 16, 16, 800)                  param = 204800 
layer 262 => conv4_block18_0_relu          (None, 16, 16, 800)                  param = 204800 
layer 263 => conv4_block18_1_conv          (None, 16, 16, 128)                  param = 32768 
layer 264 => conv4_block18_1_bn            (None, 16, 16, 128)                  param = 32768 
layer 265 => conv4_block18_1_relu          (None, 16, 16, 128)                  param = 32768 
layer 266 => conv4_block18_2_conv          (None, 16, 16, 32)                  param = 8192 
layer 267 => conv4_block18_concat          (None, 16, 16, 832)                  param = 212992 
layer 268 => conv4_block19_0_bn            (None, 16, 16, 832)                  param = 212992 
layer 269 => conv4_block19_0_relu          (None, 16, 16, 832)                  param = 212992 
layer 270 => conv4_block19_1_conv          (None, 16, 16, 128)                  param = 32768 
layer 271 => conv4_block19_1_bn            (None, 16, 16, 128)                  param = 32768 
layer 272 => conv4_block19_1_relu          (None, 16, 16, 128)                  param = 32768 
layer 273 => conv4_block19_2_conv          (None, 16, 16, 32)                  param = 8192 
layer 274 => conv4_block19_concat          (None, 16, 16, 864)                  param = 221184 
layer 275 => conv4_block20_0_bn            (None, 16, 16, 864)                  param = 221184 
layer 276 => conv4_block20_0_relu          (None, 16, 16, 864)                  param = 221184 
layer 277 => conv4_block20_1_conv          (None, 16, 16, 128)                  param = 32768 
layer 278 => conv4_block20_1_bn            (None, 16, 16, 128)                  param = 32768 
layer 279 => conv4_block20_1_relu          (None, 16, 16, 128)                  param = 32768 
layer 280 => conv4_block20_2_conv          (None, 16, 16, 32)                  param = 8192 
layer 281 => conv4_block20_concat          (None, 16, 16, 896)                  param = 229376 
layer 282 => conv4_block21_0_bn            (None, 16, 16, 896)                  param = 229376 
layer 283 => conv4_block21_0_relu          (None, 16, 16, 896)                  param = 229376 
layer 284 => conv4_block21_1_conv          (None, 16, 16, 128)                  param = 32768 
layer 285 => conv4_block21_1_bn            (None, 16, 16, 128)                  param = 32768 
layer 286 => conv4_block21_1_relu          (None, 16, 16, 128)                  param = 32768 
layer 287 => conv4_block21_2_conv          (None, 16, 16, 32)                  param = 8192 
layer 288 => conv4_block21_concat          (None, 16, 16, 928)                  param = 237568 
layer 289 => conv4_block22_0_bn            (None, 16, 16, 928)                  param = 237568 
layer 290 => conv4_block22_0_relu          (None, 16, 16, 928)                  param = 237568 
layer 291 => conv4_block22_1_conv          (None, 16, 16, 128)                  param = 32768 
layer 292 => conv4_block22_1_bn            (None, 16, 16, 128)                  param = 32768 
layer 293 => conv4_block22_1_relu          (None, 16, 16, 128)                  param = 32768 
layer 294 => conv4_block22_2_conv          (None, 16, 16, 32)                  param = 8192 
layer 295 => conv4_block22_concat          (None, 16, 16, 960)                  param = 245760 
layer 296 => conv4_block23_0_bn            (None, 16, 16, 960)                  param = 245760 
layer 297 => conv4_block23_0_relu          (None, 16, 16, 960)                  param = 245760 
layer 298 => conv4_block23_1_conv          (None, 16, 16, 128)                  param = 32768 
layer 299 => conv4_block23_1_bn            (None, 16, 16, 128)                  param = 32768 
layer 300 => conv4_block23_1_relu          (None, 16, 16, 128)                  param = 32768 
layer 301 => conv4_block23_2_conv          (None, 16, 16, 32)                  param = 8192 
layer 302 => conv4_block23_concat          (None, 16, 16, 992)                  param = 253952 
layer 303 => conv4_block24_0_bn            (None, 16, 16, 992)                  param = 253952 
layer 304 => conv4_block24_0_relu          (None, 16, 16, 992)                  param = 253952 
layer 305 => conv4_block24_1_conv          (None, 16, 16, 128)                  param = 32768 
layer 306 => conv4_block24_1_bn            (None, 16, 16, 128)                  param = 32768 
layer 307 => conv4_block24_1_relu          (None, 16, 16, 128)                  param = 32768 
layer 308 => conv4_block24_2_conv          (None, 16, 16, 32)                  param = 8192 
layer 309 => conv4_block24_concat          (None, 16, 16, 1024)                  param = 262144 
layer 310 => pool4_bn                      (None, 16, 16, 1024)                  param = 262144 
layer 311 => pool4_relu                    (None, 16, 16, 1024)                  param = 262144 
layer 312 => pool4_conv                    (None, 16, 16, 512)                  param = 131072 
layer 313 => pool4_pool                    (None, 8, 8, 512)                  param = 32768 
layer 314 => conv5_block1_0_bn             (None, 8, 8, 512)                  param = 32768 
layer 315 => conv5_block1_0_relu           (None, 8, 8, 512)                  param = 32768 
layer 316 => conv5_block1_1_conv           (None, 8, 8, 128)                  param = 8192 
layer 317 => conv5_block1_1_bn             (None, 8, 8, 128)                  param = 8192 
layer 318 => conv5_block1_1_relu           (None, 8, 8, 128)                  param = 8192 
layer 319 => conv5_block1_2_conv           (None, 8, 8, 32)                  param = 2048 
layer 320 => conv5_block1_concat           (None, 8, 8, 544)                  param = 34816 
layer 321 => conv5_block2_0_bn             (None, 8, 8, 544)                  param = 34816 
layer 322 => conv5_block2_0_relu           (None, 8, 8, 544)                  param = 34816 
layer 323 => conv5_block2_1_conv           (None, 8, 8, 128)                  param = 8192 
layer 324 => conv5_block2_1_bn             (None, 8, 8, 128)                  param = 8192 
layer 325 => conv5_block2_1_relu           (None, 8, 8, 128)                  param = 8192 
layer 326 => conv5_block2_2_conv           (None, 8, 8, 32)                  param = 2048 
layer 327 => conv5_block2_concat           (None, 8, 8, 576)                  param = 36864 
layer 328 => conv5_block3_0_bn             (None, 8, 8, 576)                  param = 36864 
layer 329 => conv5_block3_0_relu           (None, 8, 8, 576)                  param = 36864 
layer 330 => conv5_block3_1_conv           (None, 8, 8, 128)                  param = 8192 
layer 331 => conv5_block3_1_bn             (None, 8, 8, 128)                  param = 8192 
layer 332 => conv5_block3_1_relu           (None, 8, 8, 128)                  param = 8192 
layer 333 => conv5_block3_2_conv           (None, 8, 8, 32)                  param = 2048 
layer 334 => conv5_block3_concat           (None, 8, 8, 608)                  param = 38912 
layer 335 => conv5_block4_0_bn             (None, 8, 8, 608)                  param = 38912 
layer 336 => conv5_block4_0_relu           (None, 8, 8, 608)                  param = 38912 
layer 337 => conv5_block4_1_conv           (None, 8, 8, 128)                  param = 8192 
layer 338 => conv5_block4_1_bn             (None, 8, 8, 128)                  param = 8192 
layer 339 => conv5_block4_1_relu           (None, 8, 8, 128)                  param = 8192 
layer 340 => conv5_block4_2_conv           (None, 8, 8, 32)                  param = 2048 
layer 341 => conv5_block4_concat           (None, 8, 8, 640)                  param = 40960 
layer 342 => conv5_block5_0_bn             (None, 8, 8, 640)                  param = 40960 
layer 343 => conv5_block5_0_relu           (None, 8, 8, 640)                  param = 40960 
layer 344 => conv5_block5_1_conv           (None, 8, 8, 128)                  param = 8192 
layer 345 => conv5_block5_1_bn             (None, 8, 8, 128)                  param = 8192 
layer 346 => conv5_block5_1_relu           (None, 8, 8, 128)                  param = 8192 
layer 347 => conv5_block5_2_conv           (None, 8, 8, 32)                  param = 2048 
layer 348 => conv5_block5_concat           (None, 8, 8, 672)                  param = 43008 
layer 349 => conv5_block6_0_bn             (None, 8, 8, 672)                  param = 43008 
layer 350 => conv5_block6_0_relu           (None, 8, 8, 672)                  param = 43008 
layer 351 => conv5_block6_1_conv           (None, 8, 8, 128)                  param = 8192 
layer 352 => conv5_block6_1_bn             (None, 8, 8, 128)                  param = 8192 
layer 353 => conv5_block6_1_relu           (None, 8, 8, 128)                  param = 8192 
layer 354 => conv5_block6_2_conv           (None, 8, 8, 32)                  param = 2048 
layer 355 => conv5_block6_concat           (None, 8, 8, 704)                  param = 45056 
layer 356 => conv5_block7_0_bn             (None, 8, 8, 704)                  param = 45056 
layer 357 => conv5_block7_0_relu           (None, 8, 8, 704)                  param = 45056 
layer 358 => conv5_block7_1_conv           (None, 8, 8, 128)                  param = 8192 
layer 359 => conv5_block7_1_bn             (None, 8, 8, 128)                  param = 8192 
layer 360 => conv5_block7_1_relu           (None, 8, 8, 128)                  param = 8192 
layer 361 => conv5_block7_2_conv           (None, 8, 8, 32)                  param = 2048 
layer 362 => conv5_block7_concat           (None, 8, 8, 736)                  param = 47104 
layer 363 => conv5_block8_0_bn             (None, 8, 8, 736)                  param = 47104 
layer 364 => conv5_block8_0_relu           (None, 8, 8, 736)                  param = 47104 
layer 365 => conv5_block8_1_conv           (None, 8, 8, 128)                  param = 8192 
layer 366 => conv5_block8_1_bn             (None, 8, 8, 128)                  param = 8192 
layer 367 => conv5_block8_1_relu           (None, 8, 8, 128)                  param = 8192 
layer 368 => conv5_block8_2_conv           (None, 8, 8, 32)                  param = 2048 
layer 369 => conv5_block8_concat           (None, 8, 8, 768)                  param = 49152 
layer 370 => conv5_block9_0_bn             (None, 8, 8, 768)                  param = 49152 
layer 371 => conv5_block9_0_relu           (None, 8, 8, 768)                  param = 49152 
layer 372 => conv5_block9_1_conv           (None, 8, 8, 128)                  param = 8192 
layer 373 => conv5_block9_1_bn             (None, 8, 8, 128)                  param = 8192 
layer 374 => conv5_block9_1_relu           (None, 8, 8, 128)                  param = 8192 
layer 375 => conv5_block9_2_conv           (None, 8, 8, 32)                  param = 2048 
layer 376 => conv5_block9_concat           (None, 8, 8, 800)                  param = 51200 
layer 377 => conv5_block10_0_bn            (None, 8, 8, 800)                  param = 51200 
layer 378 => conv5_block10_0_relu          (None, 8, 8, 800)                  param = 51200 
layer 379 => conv5_block10_1_conv          (None, 8, 8, 128)                  param = 8192 
layer 380 => conv5_block10_1_bn            (None, 8, 8, 128)                  param = 8192 
layer 381 => conv5_block10_1_relu          (None, 8, 8, 128)                  param = 8192 
layer 382 => conv5_block10_2_conv          (None, 8, 8, 32)                  param = 2048 
layer 383 => conv5_block10_concat          (None, 8, 8, 832)                  param = 53248 
layer 384 => conv5_block11_0_bn            (None, 8, 8, 832)                  param = 53248 
layer 385 => conv5_block11_0_relu          (None, 8, 8, 832)                  param = 53248 
layer 386 => conv5_block11_1_conv          (None, 8, 8, 128)                  param = 8192 
layer 387 => conv5_block11_1_bn            (None, 8, 8, 128)                  param = 8192 
layer 388 => conv5_block11_1_relu          (None, 8, 8, 128)                  param = 8192 
layer 389 => conv5_block11_2_conv          (None, 8, 8, 32)                  param = 2048 
layer 390 => conv5_block11_concat          (None, 8, 8, 864)                  param = 55296 
layer 391 => conv5_block12_0_bn            (None, 8, 8, 864)                  param = 55296 
layer 392 => conv5_block12_0_relu          (None, 8, 8, 864)                  param = 55296 
layer 393 => conv5_block12_1_conv          (None, 8, 8, 128)                  param = 8192 
layer 394 => conv5_block12_1_bn            (None, 8, 8, 128)                  param = 8192 
layer 395 => conv5_block12_1_relu          (None, 8, 8, 128)                  param = 8192 
layer 396 => conv5_block12_2_conv          (None, 8, 8, 32)                  param = 2048 
layer 397 => conv5_block12_concat          (None, 8, 8, 896)                  param = 57344 
layer 398 => conv5_block13_0_bn            (None, 8, 8, 896)                  param = 57344 
layer 399 => conv5_block13_0_relu          (None, 8, 8, 896)                  param = 57344 
layer 400 => conv5_block13_1_conv          (None, 8, 8, 128)                  param = 8192 
layer 401 => conv5_block13_1_bn            (None, 8, 8, 128)                  param = 8192 
layer 402 => conv5_block13_1_relu          (None, 8, 8, 128)                  param = 8192 
layer 403 => conv5_block13_2_conv          (None, 8, 8, 32)                  param = 2048 
layer 404 => conv5_block13_concat          (None, 8, 8, 928)                  param = 59392 
layer 405 => conv5_block14_0_bn            (None, 8, 8, 928)                  param = 59392 
layer 406 => conv5_block14_0_relu          (None, 8, 8, 928)                  param = 59392 
layer 407 => conv5_block14_1_conv          (None, 8, 8, 128)                  param = 8192 
layer 408 => conv5_block14_1_bn            (None, 8, 8, 128)                  param = 8192 
layer 409 => conv5_block14_1_relu          (None, 8, 8, 128)                  param = 8192 
layer 410 => conv5_block14_2_conv          (None, 8, 8, 32)                  param = 2048 
layer 411 => conv5_block14_concat          (None, 8, 8, 960)                  param = 61440 
layer 412 => conv5_block15_0_bn            (None, 8, 8, 960)                  param = 61440 
layer 413 => conv5_block15_0_relu          (None, 8, 8, 960)                  param = 61440 
layer 414 => conv5_block15_1_conv          (None, 8, 8, 128)                  param = 8192 
layer 415 => conv5_block15_1_bn            (None, 8, 8, 128)                  param = 8192 
layer 416 => conv5_block15_1_relu          (None, 8, 8, 128)                  param = 8192 
layer 417 => conv5_block15_2_conv          (None, 8, 8, 32)                  param = 2048 
layer 418 => conv5_block15_concat          (None, 8, 8, 992)                  param = 63488 
layer 419 => conv5_block16_0_bn            (None, 8, 8, 992)                  param = 63488 
layer 420 => conv5_block16_0_relu          (None, 8, 8, 992)                  param = 63488 
layer 421 => conv5_block16_1_conv          (None, 8, 8, 128)                  param = 8192 
layer 422 => conv5_block16_1_bn            (None, 8, 8, 128)                  param = 8192 
layer 423 => conv5_block16_1_relu          (None, 8, 8, 128)                  param = 8192 
layer 424 => conv5_block16_2_conv          (None, 8, 8, 32)                  param = 2048 
layer 425 => conv5_block16_concat          (None, 8, 8, 1024)                  param = 65536 
layer 426 => bn                            (None, 8, 8, 1024)                  param = 65536 
layer 427 => relu                          (None, 8, 8, 1024)                  param = 65536 
layer 428 => avg_pool                      (None, 1024)                    param = 1024 
layer 429 => predictions                   (None, 1000)                    param = 1000 
