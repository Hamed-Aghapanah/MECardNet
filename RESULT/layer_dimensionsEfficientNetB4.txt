layer 1 => input_tensor                  [(None, 256, 256, 3)]                     param = 1.0 
layer 2 => rescaling_14                  (None, 256, 256, 3)                  param = 196608 
layer 3 => normalization_11              (None, 256, 256, 3)                  param = 196608 
layer 4 => stem_conv_pad                 (None, 257, 257, 3)                  param = 198147 
layer 5 => stem_conv                     (None, 128, 128, 48)                  param = 786432 
layer 6 => stem_bn                       (None, 128, 128, 48)                  param = 786432 
layer 7 => stem_activation               (None, 128, 128, 48)                  param = 786432 
layer 8 => block1a_dwconv                (None, 128, 128, 48)                  param = 786432 
layer 9 => block1a_bn                    (None, 128, 128, 48)                  param = 786432 
layer 10 => block1a_activation            (None, 128, 128, 48)                  param = 786432 
layer 11 => block1a_se_squeeze            (None, 48)                    param = 48 
layer 12 => block1a_se_reshape            (None, 1, 1, 48)                  param = 48 
layer 13 => block1a_se_reduce             (None, 1, 1, 12)                  param = 12 
layer 14 => block1a_se_expand             (None, 1, 1, 48)                  param = 48 
layer 15 => block1a_se_excite             (None, 128, 128, 48)                  param = 786432 
layer 16 => block1a_project_conv          (None, 128, 128, 24)                  param = 393216 
layer 17 => block1a_project_bn            (None, 128, 128, 24)                  param = 393216 
layer 18 => block1b_dwconv                (None, 128, 128, 24)                  param = 393216 
layer 19 => block1b_bn                    (None, 128, 128, 24)                  param = 393216 
layer 20 => block1b_activation            (None, 128, 128, 24)                  param = 393216 
layer 21 => block1b_se_squeeze            (None, 24)                    param = 24 
layer 22 => block1b_se_reshape            (None, 1, 1, 24)                  param = 24 
layer 23 => block1b_se_reduce             (None, 1, 1, 6)                  param = 6 
layer 24 => block1b_se_expand             (None, 1, 1, 24)                  param = 24 
layer 25 => block1b_se_excite             (None, 128, 128, 24)                  param = 393216 
layer 26 => block1b_project_conv          (None, 128, 128, 24)                  param = 393216 
layer 27 => block1b_project_bn            (None, 128, 128, 24)                  param = 393216 
layer 28 => block1b_drop                  (None, 128, 128, 24)                  param = 393216 
layer 29 => block1b_add                   (None, 128, 128, 24)                  param = 393216 
layer 30 => block2a_expand_conv           (None, 128, 128, 144)                  param = 2359296 
layer 31 => block2a_expand_bn             (None, 128, 128, 144)                  param = 2359296 
layer 32 => block2a_expand_activation     (None, 128, 128, 144)                  param = 2359296 
layer 33 => block2a_dwconv_pad            (None, 129, 129, 144)                  param = 2396304 
layer 34 => block2a_dwconv                (None, 64, 64, 144)                  param = 589824 
layer 35 => block2a_bn                    (None, 64, 64, 144)                  param = 589824 
layer 36 => block2a_activation            (None, 64, 64, 144)                  param = 589824 
layer 37 => block2a_se_squeeze            (None, 144)                    param = 144 
layer 38 => block2a_se_reshape            (None, 1, 1, 144)                  param = 144 
layer 39 => block2a_se_reduce             (None, 1, 1, 6)                  param = 6 
layer 40 => block2a_se_expand             (None, 1, 1, 144)                  param = 144 
layer 41 => block2a_se_excite             (None, 64, 64, 144)                  param = 589824 
layer 42 => block2a_project_conv          (None, 64, 64, 32)                  param = 131072 
layer 43 => block2a_project_bn            (None, 64, 64, 32)                  param = 131072 
layer 44 => block2b_expand_conv           (None, 64, 64, 192)                  param = 786432 
layer 45 => block2b_expand_bn             (None, 64, 64, 192)                  param = 786432 
layer 46 => block2b_expand_activation     (None, 64, 64, 192)                  param = 786432 
layer 47 => block2b_dwconv                (None, 64, 64, 192)                  param = 786432 
layer 48 => block2b_bn                    (None, 64, 64, 192)                  param = 786432 
layer 49 => block2b_activation            (None, 64, 64, 192)                  param = 786432 
layer 50 => block2b_se_squeeze            (None, 192)                    param = 192 
layer 51 => block2b_se_reshape            (None, 1, 1, 192)                  param = 192 
layer 52 => block2b_se_reduce             (None, 1, 1, 8)                  param = 8 
layer 53 => block2b_se_expand             (None, 1, 1, 192)                  param = 192 
layer 54 => block2b_se_excite             (None, 64, 64, 192)                  param = 786432 
layer 55 => block2b_project_conv          (None, 64, 64, 32)                  param = 131072 
layer 56 => block2b_project_bn            (None, 64, 64, 32)                  param = 131072 
layer 57 => block2b_drop                  (None, 64, 64, 32)                  param = 131072 
layer 58 => block2b_add                   (None, 64, 64, 32)                  param = 131072 
layer 59 => block2c_expand_conv           (None, 64, 64, 192)                  param = 786432 
layer 60 => block2c_expand_bn             (None, 64, 64, 192)                  param = 786432 
layer 61 => block2c_expand_activation     (None, 64, 64, 192)                  param = 786432 
layer 62 => block2c_dwconv                (None, 64, 64, 192)                  param = 786432 
layer 63 => block2c_bn                    (None, 64, 64, 192)                  param = 786432 
layer 64 => block2c_activation            (None, 64, 64, 192)                  param = 786432 
layer 65 => block2c_se_squeeze            (None, 192)                    param = 192 
layer 66 => block2c_se_reshape            (None, 1, 1, 192)                  param = 192 
layer 67 => block2c_se_reduce             (None, 1, 1, 8)                  param = 8 
layer 68 => block2c_se_expand             (None, 1, 1, 192)                  param = 192 
layer 69 => block2c_se_excite             (None, 64, 64, 192)                  param = 786432 
layer 70 => block2c_project_conv          (None, 64, 64, 32)                  param = 131072 
layer 71 => block2c_project_bn            (None, 64, 64, 32)                  param = 131072 
layer 72 => block2c_drop                  (None, 64, 64, 32)                  param = 131072 
layer 73 => block2c_add                   (None, 64, 64, 32)                  param = 131072 
layer 74 => block2d_expand_conv           (None, 64, 64, 192)                  param = 786432 
layer 75 => block2d_expand_bn             (None, 64, 64, 192)                  param = 786432 
layer 76 => block2d_expand_activation     (None, 64, 64, 192)                  param = 786432 
layer 77 => block2d_dwconv                (None, 64, 64, 192)                  param = 786432 
layer 78 => block2d_bn                    (None, 64, 64, 192)                  param = 786432 
layer 79 => block2d_activation            (None, 64, 64, 192)                  param = 786432 
layer 80 => block2d_se_squeeze            (None, 192)                    param = 192 
layer 81 => block2d_se_reshape            (None, 1, 1, 192)                  param = 192 
layer 82 => block2d_se_reduce             (None, 1, 1, 8)                  param = 8 
layer 83 => block2d_se_expand             (None, 1, 1, 192)                  param = 192 
layer 84 => block2d_se_excite             (None, 64, 64, 192)                  param = 786432 
layer 85 => block2d_project_conv          (None, 64, 64, 32)                  param = 131072 
layer 86 => block2d_project_bn            (None, 64, 64, 32)                  param = 131072 
layer 87 => block2d_drop                  (None, 64, 64, 32)                  param = 131072 
layer 88 => block2d_add                   (None, 64, 64, 32)                  param = 131072 
layer 89 => block3a_expand_conv           (None, 64, 64, 192)                  param = 786432 
layer 90 => block3a_expand_bn             (None, 64, 64, 192)                  param = 786432 
layer 91 => block3a_expand_activation     (None, 64, 64, 192)                  param = 786432 
layer 92 => block3a_dwconv_pad            (None, 67, 67, 192)                  param = 861888 
layer 93 => block3a_dwconv                (None, 32, 32, 192)                  param = 196608 
layer 94 => block3a_bn                    (None, 32, 32, 192)                  param = 196608 
layer 95 => block3a_activation            (None, 32, 32, 192)                  param = 196608 
layer 96 => block3a_se_squeeze            (None, 192)                    param = 192 
layer 97 => block3a_se_reshape            (None, 1, 1, 192)                  param = 192 
layer 98 => block3a_se_reduce             (None, 1, 1, 8)                  param = 8 
layer 99 => block3a_se_expand             (None, 1, 1, 192)                  param = 192 
layer 100 => block3a_se_excite             (None, 32, 32, 192)                  param = 196608 
layer 101 => block3a_project_conv          (None, 32, 32, 56)                  param = 57344 
layer 102 => block3a_project_bn            (None, 32, 32, 56)                  param = 57344 
layer 103 => block3b_expand_conv           (None, 32, 32, 336)                  param = 344064 
layer 104 => block3b_expand_bn             (None, 32, 32, 336)                  param = 344064 
layer 105 => block3b_expand_activation     (None, 32, 32, 336)                  param = 344064 
layer 106 => block3b_dwconv                (None, 32, 32, 336)                  param = 344064 
layer 107 => block3b_bn                    (None, 32, 32, 336)                  param = 344064 
layer 108 => block3b_activation            (None, 32, 32, 336)                  param = 344064 
layer 109 => block3b_se_squeeze            (None, 336)                    param = 336 
layer 110 => block3b_se_reshape            (None, 1, 1, 336)                  param = 336 
layer 111 => block3b_se_reduce             (None, 1, 1, 14)                  param = 14 
layer 112 => block3b_se_expand             (None, 1, 1, 336)                  param = 336 
layer 113 => block3b_se_excite             (None, 32, 32, 336)                  param = 344064 
layer 114 => block3b_project_conv          (None, 32, 32, 56)                  param = 57344 
layer 115 => block3b_project_bn            (None, 32, 32, 56)                  param = 57344 
layer 116 => block3b_drop                  (None, 32, 32, 56)                  param = 57344 
layer 117 => block3b_add                   (None, 32, 32, 56)                  param = 57344 
layer 118 => block3c_expand_conv           (None, 32, 32, 336)                  param = 344064 
layer 119 => block3c_expand_bn             (None, 32, 32, 336)                  param = 344064 
layer 120 => block3c_expand_activation     (None, 32, 32, 336)                  param = 344064 
layer 121 => block3c_dwconv                (None, 32, 32, 336)                  param = 344064 
layer 122 => block3c_bn                    (None, 32, 32, 336)                  param = 344064 
layer 123 => block3c_activation            (None, 32, 32, 336)                  param = 344064 
layer 124 => block3c_se_squeeze            (None, 336)                    param = 336 
layer 125 => block3c_se_reshape            (None, 1, 1, 336)                  param = 336 
layer 126 => block3c_se_reduce             (None, 1, 1, 14)                  param = 14 
layer 127 => block3c_se_expand             (None, 1, 1, 336)                  param = 336 
layer 128 => block3c_se_excite             (None, 32, 32, 336)                  param = 344064 
layer 129 => block3c_project_conv          (None, 32, 32, 56)                  param = 57344 
layer 130 => block3c_project_bn            (None, 32, 32, 56)                  param = 57344 
layer 131 => block3c_drop                  (None, 32, 32, 56)                  param = 57344 
layer 132 => block3c_add                   (None, 32, 32, 56)                  param = 57344 
layer 133 => block3d_expand_conv           (None, 32, 32, 336)                  param = 344064 
layer 134 => block3d_expand_bn             (None, 32, 32, 336)                  param = 344064 
layer 135 => block3d_expand_activation     (None, 32, 32, 336)                  param = 344064 
layer 136 => block3d_dwconv                (None, 32, 32, 336)                  param = 344064 
layer 137 => block3d_bn                    (None, 32, 32, 336)                  param = 344064 
layer 138 => block3d_activation            (None, 32, 32, 336)                  param = 344064 
layer 139 => block3d_se_squeeze            (None, 336)                    param = 336 
layer 140 => block3d_se_reshape            (None, 1, 1, 336)                  param = 336 
layer 141 => block3d_se_reduce             (None, 1, 1, 14)                  param = 14 
layer 142 => block3d_se_expand             (None, 1, 1, 336)                  param = 336 
layer 143 => block3d_se_excite             (None, 32, 32, 336)                  param = 344064 
layer 144 => block3d_project_conv          (None, 32, 32, 56)                  param = 57344 
layer 145 => block3d_project_bn            (None, 32, 32, 56)                  param = 57344 
layer 146 => block3d_drop                  (None, 32, 32, 56)                  param = 57344 
layer 147 => block3d_add                   (None, 32, 32, 56)                  param = 57344 
layer 148 => block4a_expand_conv           (None, 32, 32, 336)                  param = 344064 
layer 149 => block4a_expand_bn             (None, 32, 32, 336)                  param = 344064 
layer 150 => block4a_expand_activation     (None, 32, 32, 336)                  param = 344064 
layer 151 => block4a_dwconv_pad            (None, 33, 33, 336)                  param = 365904 
layer 152 => block4a_dwconv                (None, 16, 16, 336)                  param = 86016 
layer 153 => block4a_bn                    (None, 16, 16, 336)                  param = 86016 
layer 154 => block4a_activation            (None, 16, 16, 336)                  param = 86016 
layer 155 => block4a_se_squeeze            (None, 336)                    param = 336 
layer 156 => block4a_se_reshape            (None, 1, 1, 336)                  param = 336 
layer 157 => block4a_se_reduce             (None, 1, 1, 14)                  param = 14 
layer 158 => block4a_se_expand             (None, 1, 1, 336)                  param = 336 
layer 159 => block4a_se_excite             (None, 16, 16, 336)                  param = 86016 
layer 160 => block4a_project_conv          (None, 16, 16, 112)                  param = 28672 
layer 161 => block4a_project_bn            (None, 16, 16, 112)                  param = 28672 
layer 162 => block4b_expand_conv           (None, 16, 16, 672)                  param = 172032 
layer 163 => block4b_expand_bn             (None, 16, 16, 672)                  param = 172032 
layer 164 => block4b_expand_activation     (None, 16, 16, 672)                  param = 172032 
layer 165 => block4b_dwconv                (None, 16, 16, 672)                  param = 172032 
layer 166 => block4b_bn                    (None, 16, 16, 672)                  param = 172032 
layer 167 => block4b_activation            (None, 16, 16, 672)                  param = 172032 
layer 168 => block4b_se_squeeze            (None, 672)                    param = 672 
layer 169 => block4b_se_reshape            (None, 1, 1, 672)                  param = 672 
layer 170 => block4b_se_reduce             (None, 1, 1, 28)                  param = 28 
layer 171 => block4b_se_expand             (None, 1, 1, 672)                  param = 672 
layer 172 => block4b_se_excite             (None, 16, 16, 672)                  param = 172032 
layer 173 => block4b_project_conv          (None, 16, 16, 112)                  param = 28672 
layer 174 => block4b_project_bn            (None, 16, 16, 112)                  param = 28672 
layer 175 => block4b_drop                  (None, 16, 16, 112)                  param = 28672 
layer 176 => block4b_add                   (None, 16, 16, 112)                  param = 28672 
layer 177 => block4c_expand_conv           (None, 16, 16, 672)                  param = 172032 
layer 178 => block4c_expand_bn             (None, 16, 16, 672)                  param = 172032 
layer 179 => block4c_expand_activation     (None, 16, 16, 672)                  param = 172032 
layer 180 => block4c_dwconv                (None, 16, 16, 672)                  param = 172032 
layer 181 => block4c_bn                    (None, 16, 16, 672)                  param = 172032 
layer 182 => block4c_activation            (None, 16, 16, 672)                  param = 172032 
layer 183 => block4c_se_squeeze            (None, 672)                    param = 672 
layer 184 => block4c_se_reshape            (None, 1, 1, 672)                  param = 672 
layer 185 => block4c_se_reduce             (None, 1, 1, 28)                  param = 28 
layer 186 => block4c_se_expand             (None, 1, 1, 672)                  param = 672 
layer 187 => block4c_se_excite             (None, 16, 16, 672)                  param = 172032 
layer 188 => block4c_project_conv          (None, 16, 16, 112)                  param = 28672 
layer 189 => block4c_project_bn            (None, 16, 16, 112)                  param = 28672 
layer 190 => block4c_drop                  (None, 16, 16, 112)                  param = 28672 
layer 191 => block4c_add                   (None, 16, 16, 112)                  param = 28672 
layer 192 => block4d_expand_conv           (None, 16, 16, 672)                  param = 172032 
layer 193 => block4d_expand_bn             (None, 16, 16, 672)                  param = 172032 
layer 194 => block4d_expand_activation     (None, 16, 16, 672)                  param = 172032 
layer 195 => block4d_dwconv                (None, 16, 16, 672)                  param = 172032 
layer 196 => block4d_bn                    (None, 16, 16, 672)                  param = 172032 
layer 197 => block4d_activation            (None, 16, 16, 672)                  param = 172032 
layer 198 => block4d_se_squeeze            (None, 672)                    param = 672 
layer 199 => block4d_se_reshape            (None, 1, 1, 672)                  param = 672 
layer 200 => block4d_se_reduce             (None, 1, 1, 28)                  param = 28 
layer 201 => block4d_se_expand             (None, 1, 1, 672)                  param = 672 
layer 202 => block4d_se_excite             (None, 16, 16, 672)                  param = 172032 
layer 203 => block4d_project_conv          (None, 16, 16, 112)                  param = 28672 
layer 204 => block4d_project_bn            (None, 16, 16, 112)                  param = 28672 
layer 205 => block4d_drop                  (None, 16, 16, 112)                  param = 28672 
layer 206 => block4d_add                   (None, 16, 16, 112)                  param = 28672 
layer 207 => block4e_expand_conv           (None, 16, 16, 672)                  param = 172032 
layer 208 => block4e_expand_bn             (None, 16, 16, 672)                  param = 172032 
layer 209 => block4e_expand_activation     (None, 16, 16, 672)                  param = 172032 
layer 210 => block4e_dwconv                (None, 16, 16, 672)                  param = 172032 
layer 211 => block4e_bn                    (None, 16, 16, 672)                  param = 172032 
layer 212 => block4e_activation            (None, 16, 16, 672)                  param = 172032 
layer 213 => block4e_se_squeeze            (None, 672)                    param = 672 
layer 214 => block4e_se_reshape            (None, 1, 1, 672)                  param = 672 
layer 215 => block4e_se_reduce             (None, 1, 1, 28)                  param = 28 
layer 216 => block4e_se_expand             (None, 1, 1, 672)                  param = 672 
layer 217 => block4e_se_excite             (None, 16, 16, 672)                  param = 172032 
layer 218 => block4e_project_conv          (None, 16, 16, 112)                  param = 28672 
layer 219 => block4e_project_bn            (None, 16, 16, 112)                  param = 28672 
layer 220 => block4e_drop                  (None, 16, 16, 112)                  param = 28672 
layer 221 => block4e_add                   (None, 16, 16, 112)                  param = 28672 
layer 222 => block4f_expand_conv           (None, 16, 16, 672)                  param = 172032 
layer 223 => block4f_expand_bn             (None, 16, 16, 672)                  param = 172032 
layer 224 => block4f_expand_activation     (None, 16, 16, 672)                  param = 172032 
layer 225 => block4f_dwconv                (None, 16, 16, 672)                  param = 172032 
layer 226 => block4f_bn                    (None, 16, 16, 672)                  param = 172032 
layer 227 => block4f_activation            (None, 16, 16, 672)                  param = 172032 
layer 228 => block4f_se_squeeze            (None, 672)                    param = 672 
layer 229 => block4f_se_reshape            (None, 1, 1, 672)                  param = 672 
layer 230 => block4f_se_reduce             (None, 1, 1, 28)                  param = 28 
layer 231 => block4f_se_expand             (None, 1, 1, 672)                  param = 672 
layer 232 => block4f_se_excite             (None, 16, 16, 672)                  param = 172032 
layer 233 => block4f_project_conv          (None, 16, 16, 112)                  param = 28672 
layer 234 => block4f_project_bn            (None, 16, 16, 112)                  param = 28672 
layer 235 => block4f_drop                  (None, 16, 16, 112)                  param = 28672 
layer 236 => block4f_add                   (None, 16, 16, 112)                  param = 28672 
layer 237 => block5a_expand_conv           (None, 16, 16, 672)                  param = 172032 
layer 238 => block5a_expand_bn             (None, 16, 16, 672)                  param = 172032 
layer 239 => block5a_expand_activation     (None, 16, 16, 672)                  param = 172032 
layer 240 => block5a_dwconv                (None, 16, 16, 672)                  param = 172032 
layer 241 => block5a_bn                    (None, 16, 16, 672)                  param = 172032 
layer 242 => block5a_activation            (None, 16, 16, 672)                  param = 172032 
layer 243 => block5a_se_squeeze            (None, 672)                    param = 672 
layer 244 => block5a_se_reshape            (None, 1, 1, 672)                  param = 672 
layer 245 => block5a_se_reduce             (None, 1, 1, 28)                  param = 28 
layer 246 => block5a_se_expand             (None, 1, 1, 672)                  param = 672 
layer 247 => block5a_se_excite             (None, 16, 16, 672)                  param = 172032 
layer 248 => block5a_project_conv          (None, 16, 16, 160)                  param = 40960 
layer 249 => block5a_project_bn            (None, 16, 16, 160)                  param = 40960 
layer 250 => block5b_expand_conv           (None, 16, 16, 960)                  param = 245760 
layer 251 => block5b_expand_bn             (None, 16, 16, 960)                  param = 245760 
layer 252 => block5b_expand_activation     (None, 16, 16, 960)                  param = 245760 
layer 253 => block5b_dwconv                (None, 16, 16, 960)                  param = 245760 
layer 254 => block5b_bn                    (None, 16, 16, 960)                  param = 245760 
layer 255 => block5b_activation            (None, 16, 16, 960)                  param = 245760 
layer 256 => block5b_se_squeeze            (None, 960)                    param = 960 
layer 257 => block5b_se_reshape            (None, 1, 1, 960)                  param = 960 
layer 258 => block5b_se_reduce             (None, 1, 1, 40)                  param = 40 
layer 259 => block5b_se_expand             (None, 1, 1, 960)                  param = 960 
layer 260 => block5b_se_excite             (None, 16, 16, 960)                  param = 245760 
layer 261 => block5b_project_conv          (None, 16, 16, 160)                  param = 40960 
layer 262 => block5b_project_bn            (None, 16, 16, 160)                  param = 40960 
layer 263 => block5b_drop                  (None, 16, 16, 160)                  param = 40960 
layer 264 => block5b_add                   (None, 16, 16, 160)                  param = 40960 
layer 265 => block5c_expand_conv           (None, 16, 16, 960)                  param = 245760 
layer 266 => block5c_expand_bn             (None, 16, 16, 960)                  param = 245760 
layer 267 => block5c_expand_activation     (None, 16, 16, 960)                  param = 245760 
layer 268 => block5c_dwconv                (None, 16, 16, 960)                  param = 245760 
layer 269 => block5c_bn                    (None, 16, 16, 960)                  param = 245760 
layer 270 => block5c_activation            (None, 16, 16, 960)                  param = 245760 
layer 271 => block5c_se_squeeze            (None, 960)                    param = 960 
layer 272 => block5c_se_reshape            (None, 1, 1, 960)                  param = 960 
layer 273 => block5c_se_reduce             (None, 1, 1, 40)                  param = 40 
layer 274 => block5c_se_expand             (None, 1, 1, 960)                  param = 960 
layer 275 => block5c_se_excite             (None, 16, 16, 960)                  param = 245760 
layer 276 => block5c_project_conv          (None, 16, 16, 160)                  param = 40960 
layer 277 => block5c_project_bn            (None, 16, 16, 160)                  param = 40960 
layer 278 => block5c_drop                  (None, 16, 16, 160)                  param = 40960 
layer 279 => block5c_add                   (None, 16, 16, 160)                  param = 40960 
layer 280 => block5d_expand_conv           (None, 16, 16, 960)                  param = 245760 
layer 281 => block5d_expand_bn             (None, 16, 16, 960)                  param = 245760 
layer 282 => block5d_expand_activation     (None, 16, 16, 960)                  param = 245760 
layer 283 => block5d_dwconv                (None, 16, 16, 960)                  param = 245760 
layer 284 => block5d_bn                    (None, 16, 16, 960)                  param = 245760 
layer 285 => block5d_activation            (None, 16, 16, 960)                  param = 245760 
layer 286 => block5d_se_squeeze            (None, 960)                    param = 960 
layer 287 => block5d_se_reshape            (None, 1, 1, 960)                  param = 960 
layer 288 => block5d_se_reduce             (None, 1, 1, 40)                  param = 40 
layer 289 => block5d_se_expand             (None, 1, 1, 960)                  param = 960 
layer 290 => block5d_se_excite             (None, 16, 16, 960)                  param = 245760 
layer 291 => block5d_project_conv          (None, 16, 16, 160)                  param = 40960 
layer 292 => block5d_project_bn            (None, 16, 16, 160)                  param = 40960 
layer 293 => block5d_drop                  (None, 16, 16, 160)                  param = 40960 
layer 294 => block5d_add                   (None, 16, 16, 160)                  param = 40960 
layer 295 => block5e_expand_conv           (None, 16, 16, 960)                  param = 245760 
layer 296 => block5e_expand_bn             (None, 16, 16, 960)                  param = 245760 
layer 297 => block5e_expand_activation     (None, 16, 16, 960)                  param = 245760 
layer 298 => block5e_dwconv                (None, 16, 16, 960)                  param = 245760 
layer 299 => block5e_bn                    (None, 16, 16, 960)                  param = 245760 
layer 300 => block5e_activation            (None, 16, 16, 960)                  param = 245760 
layer 301 => block5e_se_squeeze            (None, 960)                    param = 960 
layer 302 => block5e_se_reshape            (None, 1, 1, 960)                  param = 960 
layer 303 => block5e_se_reduce             (None, 1, 1, 40)                  param = 40 
layer 304 => block5e_se_expand             (None, 1, 1, 960)                  param = 960 
layer 305 => block5e_se_excite             (None, 16, 16, 960)                  param = 245760 
layer 306 => block5e_project_conv          (None, 16, 16, 160)                  param = 40960 
layer 307 => block5e_project_bn            (None, 16, 16, 160)                  param = 40960 
layer 308 => block5e_drop                  (None, 16, 16, 160)                  param = 40960 
layer 309 => block5e_add                   (None, 16, 16, 160)                  param = 40960 
layer 310 => block5f_expand_conv           (None, 16, 16, 960)                  param = 245760 
layer 311 => block5f_expand_bn             (None, 16, 16, 960)                  param = 245760 
layer 312 => block5f_expand_activation     (None, 16, 16, 960)                  param = 245760 
layer 313 => block5f_dwconv                (None, 16, 16, 960)                  param = 245760 
layer 314 => block5f_bn                    (None, 16, 16, 960)                  param = 245760 
layer 315 => block5f_activation            (None, 16, 16, 960)                  param = 245760 
layer 316 => block5f_se_squeeze            (None, 960)                    param = 960 
layer 317 => block5f_se_reshape            (None, 1, 1, 960)                  param = 960 
layer 318 => block5f_se_reduce             (None, 1, 1, 40)                  param = 40 
layer 319 => block5f_se_expand             (None, 1, 1, 960)                  param = 960 
layer 320 => block5f_se_excite             (None, 16, 16, 960)                  param = 245760 
layer 321 => block5f_project_conv          (None, 16, 16, 160)                  param = 40960 
layer 322 => block5f_project_bn            (None, 16, 16, 160)                  param = 40960 
layer 323 => block5f_drop                  (None, 16, 16, 160)                  param = 40960 
layer 324 => block5f_add                   (None, 16, 16, 160)                  param = 40960 
layer 325 => block6a_expand_conv           (None, 16, 16, 960)                  param = 245760 
layer 326 => block6a_expand_bn             (None, 16, 16, 960)                  param = 245760 
layer 327 => block6a_expand_activation     (None, 16, 16, 960)                  param = 245760 
layer 328 => block6a_dwconv_pad            (None, 19, 19, 960)                  param = 346560 
layer 329 => block6a_dwconv                (None, 8, 8, 960)                  param = 61440 
layer 330 => block6a_bn                    (None, 8, 8, 960)                  param = 61440 
layer 331 => block6a_activation            (None, 8, 8, 960)                  param = 61440 
layer 332 => block6a_se_squeeze            (None, 960)                    param = 960 
layer 333 => block6a_se_reshape            (None, 1, 1, 960)                  param = 960 
layer 334 => block6a_se_reduce             (None, 1, 1, 40)                  param = 40 
layer 335 => block6a_se_expand             (None, 1, 1, 960)                  param = 960 
layer 336 => block6a_se_excite             (None, 8, 8, 960)                  param = 61440 
layer 337 => block6a_project_conv          (None, 8, 8, 272)                  param = 17408 
layer 338 => block6a_project_bn            (None, 8, 8, 272)                  param = 17408 
layer 339 => block6b_expand_conv           (None, 8, 8, 1632)                  param = 104448 
layer 340 => block6b_expand_bn             (None, 8, 8, 1632)                  param = 104448 
layer 341 => block6b_expand_activation     (None, 8, 8, 1632)                  param = 104448 
layer 342 => block6b_dwconv                (None, 8, 8, 1632)                  param = 104448 
layer 343 => block6b_bn                    (None, 8, 8, 1632)                  param = 104448 
layer 344 => block6b_activation            (None, 8, 8, 1632)                  param = 104448 
layer 345 => block6b_se_squeeze            (None, 1632)                    param = 1632 
layer 346 => block6b_se_reshape            (None, 1, 1, 1632)                  param = 1632 
layer 347 => block6b_se_reduce             (None, 1, 1, 68)                  param = 68 
layer 348 => block6b_se_expand             (None, 1, 1, 1632)                  param = 1632 
layer 349 => block6b_se_excite             (None, 8, 8, 1632)                  param = 104448 
layer 350 => block6b_project_conv          (None, 8, 8, 272)                  param = 17408 
layer 351 => block6b_project_bn            (None, 8, 8, 272)                  param = 17408 
layer 352 => block6b_drop                  (None, 8, 8, 272)                  param = 17408 
layer 353 => block6b_add                   (None, 8, 8, 272)                  param = 17408 
layer 354 => block6c_expand_conv           (None, 8, 8, 1632)                  param = 104448 
layer 355 => block6c_expand_bn             (None, 8, 8, 1632)                  param = 104448 
layer 356 => block6c_expand_activation     (None, 8, 8, 1632)                  param = 104448 
layer 357 => block6c_dwconv                (None, 8, 8, 1632)                  param = 104448 
layer 358 => block6c_bn                    (None, 8, 8, 1632)                  param = 104448 
layer 359 => block6c_activation            (None, 8, 8, 1632)                  param = 104448 
layer 360 => block6c_se_squeeze            (None, 1632)                    param = 1632 
layer 361 => block6c_se_reshape            (None, 1, 1, 1632)                  param = 1632 
layer 362 => block6c_se_reduce             (None, 1, 1, 68)                  param = 68 
layer 363 => block6c_se_expand             (None, 1, 1, 1632)                  param = 1632 
layer 364 => block6c_se_excite             (None, 8, 8, 1632)                  param = 104448 
layer 365 => block6c_project_conv          (None, 8, 8, 272)                  param = 17408 
layer 366 => block6c_project_bn            (None, 8, 8, 272)                  param = 17408 
layer 367 => block6c_drop                  (None, 8, 8, 272)                  param = 17408 
layer 368 => block6c_add                   (None, 8, 8, 272)                  param = 17408 
layer 369 => block6d_expand_conv           (None, 8, 8, 1632)                  param = 104448 
layer 370 => block6d_expand_bn             (None, 8, 8, 1632)                  param = 104448 
layer 371 => block6d_expand_activation     (None, 8, 8, 1632)                  param = 104448 
layer 372 => block6d_dwconv                (None, 8, 8, 1632)                  param = 104448 
layer 373 => block6d_bn                    (None, 8, 8, 1632)                  param = 104448 
layer 374 => block6d_activation            (None, 8, 8, 1632)                  param = 104448 
layer 375 => block6d_se_squeeze            (None, 1632)                    param = 1632 
layer 376 => block6d_se_reshape            (None, 1, 1, 1632)                  param = 1632 
layer 377 => block6d_se_reduce             (None, 1, 1, 68)                  param = 68 
layer 378 => block6d_se_expand             (None, 1, 1, 1632)                  param = 1632 
layer 379 => block6d_se_excite             (None, 8, 8, 1632)                  param = 104448 
layer 380 => block6d_project_conv          (None, 8, 8, 272)                  param = 17408 
layer 381 => block6d_project_bn            (None, 8, 8, 272)                  param = 17408 
layer 382 => block6d_drop                  (None, 8, 8, 272)                  param = 17408 
layer 383 => block6d_add                   (None, 8, 8, 272)                  param = 17408 
layer 384 => block6e_expand_conv           (None, 8, 8, 1632)                  param = 104448 
layer 385 => block6e_expand_bn             (None, 8, 8, 1632)                  param = 104448 
layer 386 => block6e_expand_activation     (None, 8, 8, 1632)                  param = 104448 
layer 387 => block6e_dwconv                (None, 8, 8, 1632)                  param = 104448 
layer 388 => block6e_bn                    (None, 8, 8, 1632)                  param = 104448 
layer 389 => block6e_activation            (None, 8, 8, 1632)                  param = 104448 
layer 390 => block6e_se_squeeze            (None, 1632)                    param = 1632 
layer 391 => block6e_se_reshape            (None, 1, 1, 1632)                  param = 1632 
layer 392 => block6e_se_reduce             (None, 1, 1, 68)                  param = 68 
layer 393 => block6e_se_expand             (None, 1, 1, 1632)                  param = 1632 
layer 394 => block6e_se_excite             (None, 8, 8, 1632)                  param = 104448 
layer 395 => block6e_project_conv          (None, 8, 8, 272)                  param = 17408 
layer 396 => block6e_project_bn            (None, 8, 8, 272)                  param = 17408 
layer 397 => block6e_drop                  (None, 8, 8, 272)                  param = 17408 
layer 398 => block6e_add                   (None, 8, 8, 272)                  param = 17408 
layer 399 => block6f_expand_conv           (None, 8, 8, 1632)                  param = 104448 
layer 400 => block6f_expand_bn             (None, 8, 8, 1632)                  param = 104448 
layer 401 => block6f_expand_activation     (None, 8, 8, 1632)                  param = 104448 
layer 402 => block6f_dwconv                (None, 8, 8, 1632)                  param = 104448 
layer 403 => block6f_bn                    (None, 8, 8, 1632)                  param = 104448 
layer 404 => block6f_activation            (None, 8, 8, 1632)                  param = 104448 
layer 405 => block6f_se_squeeze            (None, 1632)                    param = 1632 
layer 406 => block6f_se_reshape            (None, 1, 1, 1632)                  param = 1632 
layer 407 => block6f_se_reduce             (None, 1, 1, 68)                  param = 68 
layer 408 => block6f_se_expand             (None, 1, 1, 1632)                  param = 1632 
layer 409 => block6f_se_excite             (None, 8, 8, 1632)                  param = 104448 
layer 410 => block6f_project_conv          (None, 8, 8, 272)                  param = 17408 
layer 411 => block6f_project_bn            (None, 8, 8, 272)                  param = 17408 
layer 412 => block6f_drop                  (None, 8, 8, 272)                  param = 17408 
layer 413 => block6f_add                   (None, 8, 8, 272)                  param = 17408 
layer 414 => block6g_expand_conv           (None, 8, 8, 1632)                  param = 104448 
layer 415 => block6g_expand_bn             (None, 8, 8, 1632)                  param = 104448 
layer 416 => block6g_expand_activation     (None, 8, 8, 1632)                  param = 104448 
layer 417 => block6g_dwconv                (None, 8, 8, 1632)                  param = 104448 
layer 418 => block6g_bn                    (None, 8, 8, 1632)                  param = 104448 
layer 419 => block6g_activation            (None, 8, 8, 1632)                  param = 104448 
layer 420 => block6g_se_squeeze            (None, 1632)                    param = 1632 
layer 421 => block6g_se_reshape            (None, 1, 1, 1632)                  param = 1632 
layer 422 => block6g_se_reduce             (None, 1, 1, 68)                  param = 68 
layer 423 => block6g_se_expand             (None, 1, 1, 1632)                  param = 1632 
layer 424 => block6g_se_excite             (None, 8, 8, 1632)                  param = 104448 
layer 425 => block6g_project_conv          (None, 8, 8, 272)                  param = 17408 
layer 426 => block6g_project_bn            (None, 8, 8, 272)                  param = 17408 
layer 427 => block6g_drop                  (None, 8, 8, 272)                  param = 17408 
layer 428 => block6g_add                   (None, 8, 8, 272)                  param = 17408 
layer 429 => block6h_expand_conv           (None, 8, 8, 1632)                  param = 104448 
layer 430 => block6h_expand_bn             (None, 8, 8, 1632)                  param = 104448 
layer 431 => block6h_expand_activation     (None, 8, 8, 1632)                  param = 104448 
layer 432 => block6h_dwconv                (None, 8, 8, 1632)                  param = 104448 
layer 433 => block6h_bn                    (None, 8, 8, 1632)                  param = 104448 
layer 434 => block6h_activation            (None, 8, 8, 1632)                  param = 104448 
layer 435 => block6h_se_squeeze            (None, 1632)                    param = 1632 
layer 436 => block6h_se_reshape            (None, 1, 1, 1632)                  param = 1632 
layer 437 => block6h_se_reduce             (None, 1, 1, 68)                  param = 68 
layer 438 => block6h_se_expand             (None, 1, 1, 1632)                  param = 1632 
layer 439 => block6h_se_excite             (None, 8, 8, 1632)                  param = 104448 
layer 440 => block6h_project_conv          (None, 8, 8, 272)                  param = 17408 
layer 441 => block6h_project_bn            (None, 8, 8, 272)                  param = 17408 
layer 442 => block6h_drop                  (None, 8, 8, 272)                  param = 17408 
layer 443 => block6h_add                   (None, 8, 8, 272)                  param = 17408 
layer 444 => block7a_expand_conv           (None, 8, 8, 1632)                  param = 104448 
layer 445 => block7a_expand_bn             (None, 8, 8, 1632)                  param = 104448 
layer 446 => block7a_expand_activation     (None, 8, 8, 1632)                  param = 104448 
layer 447 => block7a_dwconv                (None, 8, 8, 1632)                  param = 104448 
layer 448 => block7a_bn                    (None, 8, 8, 1632)                  param = 104448 
layer 449 => block7a_activation            (None, 8, 8, 1632)                  param = 104448 
layer 450 => block7a_se_squeeze            (None, 1632)                    param = 1632 
layer 451 => block7a_se_reshape            (None, 1, 1, 1632)                  param = 1632 
layer 452 => block7a_se_reduce             (None, 1, 1, 68)                  param = 68 
layer 453 => block7a_se_expand             (None, 1, 1, 1632)                  param = 1632 
layer 454 => block7a_se_excite             (None, 8, 8, 1632)                  param = 104448 
layer 455 => block7a_project_conv          (None, 8, 8, 448)                  param = 28672 
layer 456 => block7a_project_bn            (None, 8, 8, 448)                  param = 28672 
layer 457 => block7b_expand_conv           (None, 8, 8, 2688)                  param = 172032 
layer 458 => block7b_expand_bn             (None, 8, 8, 2688)                  param = 172032 
layer 459 => block7b_expand_activation     (None, 8, 8, 2688)                  param = 172032 
layer 460 => block7b_dwconv                (None, 8, 8, 2688)                  param = 172032 
layer 461 => block7b_bn                    (None, 8, 8, 2688)                  param = 172032 
layer 462 => block7b_activation            (None, 8, 8, 2688)                  param = 172032 
layer 463 => block7b_se_squeeze            (None, 2688)                    param = 2688 
layer 464 => block7b_se_reshape            (None, 1, 1, 2688)                  param = 2688 
layer 465 => block7b_se_reduce             (None, 1, 1, 112)                  param = 112 
layer 466 => block7b_se_expand             (None, 1, 1, 2688)                  param = 2688 
layer 467 => block7b_se_excite             (None, 8, 8, 2688)                  param = 172032 
layer 468 => block7b_project_conv          (None, 8, 8, 448)                  param = 28672 
layer 469 => block7b_project_bn            (None, 8, 8, 448)                  param = 28672 
layer 470 => block7b_drop                  (None, 8, 8, 448)                  param = 28672 
layer 471 => block7b_add                   (None, 8, 8, 448)                  param = 28672 
layer 472 => top_conv                      (None, 8, 8, 1792)                  param = 114688 
layer 473 => top_bn                        (None, 8, 8, 1792)                  param = 114688 
layer 474 => top_activation                (None, 8, 8, 1792)                  param = 114688 
layer 475 => avg_pool                      (None, 1792)                    param = 1792 
layer 476 => top_dropout                   (None, 1792)                    param = 1792 
layer 477 => predictions                   (None, 1000)                    param = 1000 
